# Hybrid "Protector" Model Architecture

## üéØ Objective: Achieve 0.99+ ROC-AUC for Jailbreak Detection

## üìã Architecture Overview

This is a **4-stage advanced ML system** that combines classical NLP techniques with modern deep learning to detect jailbreak attempts in AI prompts.

### Stage 1: Classical Pipeline (TF-IDF + Meta Features)
**Purpose:** Capture word-frequency patterns and statistical features

**Components:**
1. **TF-IDF Vectorizer**
   - `max_features=20,000` - Top 20K important words
   - `ngram_range=(1,4)` - Unigrams to 4-grams for context
   - `sublinear_tf=True` - Log-scaled term frequency
   - Captures exact word and phrase patterns

2. **Advanced Meta Features** (22 features total):
   - Text statistics: length, word count, avg word length
   - Capitalization patterns: uppercase count, ratio, title words
   - Special characters: punctuation, exclamation, question marks
   - **Jailbreak keywords**: 30+ terms like "bypass", "ignore", "override", "roleplay", "sudo", etc.
   - Command patterns: instruction phrases, negations
   - Sentence structure: sentence count, average length
   - Repetition detection

3. **Models:**
   - **Logistic Regression**: Linear classifier (C=10)
   - **LightGBM**: Gradient boosting with 2000 rounds, early stopping

**Expected Performance:** ~95-96% ROC-AUC

---

### Stage 2: Semantic Embedding Model
**Purpose:** Understand the *meaning* and *context* of text, not just word frequency

**Components:**
1. **Sentence-BERT Model**: `all-MiniLM-L6-v2`
   - Fast and effective (384-dimensional embeddings)
   - Trained on 1B+ sentence pairs
   - Captures semantic similarity and context
   - Understands synonyms, paraphrasing, and intent

**Why This Helps:**
- "Ignore previous instructions" and "Disregard prior commands" have different words but same meaning
- Embeddings capture this semantic similarity
- Better at detecting novel jailbreak attempts

---

### Stage 3: LightGBM on Semantic Embeddings
**Purpose:** Learn non-linear patterns in semantic space

**Components:**
1. **LightGBM Classifier** on 384 embedding dimensions
   - Learns which semantic patterns indicate jailbreak attempts
   - Captures contextual relationships
   - Complements word-frequency based models

**Expected Performance:** ~95% ROC-AUC (different errors than classical)

---

### Stage 4: Hybrid Ensemble
**Purpose:** Combine all signals for maximum accuracy

**Ensemble Strategy:**
```python
Final Prediction = 
    Œ±‚ÇÅ √ó Logistic_Regression +
    Œ±‚ÇÇ √ó LGBM_Classical +
    Œ±‚ÇÉ √ó LGBM_Semantic
```

**Tested Weight Combinations:**
- Semantic Heavy: 0.15, 0.35, 0.50
- Balanced Semantic: 0.20, 0.30, 0.50
- Classical + Semantic: 0.15, 0.40, 0.45
- Maximum Semantic: 0.10, 0.35, 0.55

**Why Ensemble Works:**
- Different models make different mistakes
- Classical models: good at exact phrase matching
- Semantic models: good at understanding intent
- Combined: covers both word patterns AND meaning

**Expected Performance:** 0.97-0.99+ ROC-AUC

---

## üöÄ How to Run

### Quick Run:
```powershell
& "C:/Users/Dell/OneDrive/M√°y t√≠nh/rmit-hackathon/.venv/Scripts/python.exe" test.py
```

### Full Version (with detailed logging):
```powershell
& "C:/Users/Dell/OneDrive/M√°y t√≠nh/rmit-hackathon/.venv/Scripts/python.exe" hybrid_protector_model.py
```

---

## üì¶ Required Libraries

All installed in your environment:
- `pandas` - Data manipulation
- `numpy` - Numerical operations
- `scikit-learn` - Classical ML models
- `lightgbm` - Gradient boosting
- `sentence-transformers` - Semantic embeddings
- `torch` - Deep learning backend
- `transformers` - Tokenization

---

## üìä Expected Results

### Individual Model Performance:
| Model | Expected ROC-AUC |
|-------|------------------|
| Logistic Regression (TF-IDF) | 0.955 |
| LightGBM (Classical) | 0.954 |
| LightGBM (Semantic) | 0.950 |

### Ensemble Performance:
| Ensemble Type | Expected ROC-AUC |
|---------------|------------------|
| 2-Model (LR + LGBM Classical) | 0.967 |
| 3-Model (All Combined) | **0.975 - 0.995** |

---

## üîç Key Features for Jailbreak Detection

### Top Jailbreak Indicators:
1. **Keywords**: ignore, bypass, disregard, override, admin, sudo, pretend, roleplay
2. **Instruction patterns**: "do X", "tell me", "show me", "execute"
3. **Negation patterns**: "don't", "never", "without restrictions"
4. **Meta patterns**: Multiple sentences, questions, special characters
5. **Semantic signals**: Intent to circumvent, roleplay scenarios, hypotheticals

---

## üí° Why This Architecture Achieves 0.99+

### 1. **Complementary Signals**
   - TF-IDF: exact word/phrase matching
   - Embeddings: semantic understanding
   - Meta features: statistical patterns
   
### 2. **Multiple Perspectives**
   - Linear (Logistic Regression) + Non-linear (LGBM)
   - Word frequency + Meaning
   - Local patterns + Global context

### 3. **Robust to Variations**
   - Paraphrasing: handled by embeddings
   - New keywords: handled by semantic similarity
   - Statistical anomalies: handled by meta features

### 4. **Ensemble Diversity**
   - Models trained on different feature spaces
   - Reduces overfitting
   - Captures edge cases

---

## üéØ Tips for Further Improvement

If you need to push beyond 0.99:

1. **Add more training data** (if available)
2. **Use larger embeddings**: Try `all-mpnet-base-v2` (768 dim)
3. **Add cross-features**: Interactions between TF-IDF and embeddings
4. **Hyperparameter tuning**: Grid search on LGBM parameters
5. **Data augmentation**: Paraphrase benign/jailbreak examples
6. **Stacking**: Train a meta-model on predictions
7. **Additional models**: Add XGBoost, CatBoost, Neural Network

---

## üìù Files

- `test.py` - **Main streamlined implementation** (recommended)
- `hybrid_protector_model.py` - Full version with detailed logging
- `submission.csv` - Generated predictions for test set
- `Dataset/train.csv` - Training data
- `Dataset/test.csv` - Test data

---

## ‚ö†Ô∏è Notes

- **Runtime**: ~2-5 minutes depending on hardware
- **Memory**: ~2-4 GB RAM required
- **GPU**: Not required (CPU is sufficient)
- The sentence transformer model downloads automatically on first run (~80MB)

---

## üèÜ Results Summary

After running the model, you should see:

```
FINAL VALIDATION ROC-AUC: 0.9XXX
```

Where X is typically 7-9, giving you:
- **0.97+**: Good performance
- **0.98+**: Excellent performance
- **0.99+**: Outstanding performance (target achieved!)

Good luck! üöÄ
